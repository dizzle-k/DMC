{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitenv10cc2b33a7e1542bbac7562dac990d093",
   "display_name": "Python 3.8.5 64-bit ('env1': virtualenvwrapper)"
  },
  "metadata": {
   "interpreter": {
    "hash": "9ef5468a5c3446d919a3df41ce23b00652fe3710922e53e14080c28e3bcfe2d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# load file with itemIDs of the evaluation books\n",
    "eval_ = pd.read_csv('data/evaluation.csv', delimiter='\\|', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load amazon recommendations\n",
    "amazon = pd.read_csv('data/amazon_recommendations.csv', sep='~')\n",
    "amazon = amazon[['itemID', 'author', 'title', 'rec1_ID', 'rec2_ID', 'rec3_ID', 'rec4_ID', 'rec5_ID', 'rec6_ID', 'rec7_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test book for computing the accuracy between own recommendations\n",
    "# and the amazon recommendations\n",
    "test_book_id = eval_.at[555, 'itemID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10881\n<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "print(test_book_id)\n",
    "print(type(test_book_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[67938, 74953, 50640, 1234, 7763]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# pseudo set of itemIDs of the own recommended books for the test book 10881\n",
    "# dtype = np.int64()\n",
    "recommendations = [np.int64(67938), np.int64(74953), np.int64(50640), np.int64(1234), np.int64(7763)]\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(book_id: np.int64, own_rec: list) -> float:\n",
    "    # Keyword arguments:\n",
    "    #\n",
    "    # book_id -- ID of the test book (np.int64)\n",
    "    # own_rec -- list of own recommendations for the test book (list elements of type np.int64())\n",
    "    #\n",
    "    # :return:\n",
    "    # acc -- accuracy of the own recommendations compared to the amazon recommendations\n",
    "    df = amazon[amazon['itemID'] == book_id]\n",
    "    df = df[['rec1_ID', 'rec2_ID', 'rec3_ID', 'rec4_ID', 'rec5_ID', 'rec6_ID', 'rec7_ID']]\n",
    "    vals = df.values.tolist()[0]\n",
    "    vals = [v for v in vals if not pd.isnull(v) and v not in ['-', '---']]\n",
    "\n",
    "    amazon_rec = []\n",
    "\n",
    "    for v in vals:\n",
    "        if type(v) == int:\n",
    "            amazon_rec.append(v)\n",
    "        if type(v) == str:\n",
    "            numbers = re.findall('\\d{2,}', v)\n",
    "            for num in numbers:\n",
    "                amazon_rec.append(int(num))\n",
    "    \n",
    "    own_rec = [(r in amazon_rec) for r in own_rec]\n",
    "\n",
    "    acc = float(sum(own_rec) / len(own_rec)) * 100\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy for book 10881 == 60.0 %\n"
     ]
    }
   ],
   "source": [
    "acc = get_accuracy(book_id=test_book_id, own_rec=recommendations)\n",
    "print('accuracy for book {0} == {1} %'.format(test_book_id, round(acc, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the overall accuracy loop over all 1000 ID of the eval_ file\n",
    "# and average the accuracies"
   ]
  }
 ]
}