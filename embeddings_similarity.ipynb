{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv(\"items.csv\", delimiter=\"\\|\", engine=\"python\")\n",
    "items_c = pd.read_csv(\"items_stopc.csv\", delimiter=\"\\|\", engine=\"python\")\n",
    "items_dedup_c = pd.read_csv(\"items_dedup_stopc.csv\", delimiter=\"\\|\", engine=\"python\")\n",
    "eval_ = pd.read_csv(\"evaluation.csv\", delimiter=\"\\|\", engine=\"python\")\n",
    "\n",
    "convert_dict = {\"itemID\": np.int64}\n",
    "\n",
    "eval_ = eval_.astype(convert_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_val = pd.read_csv(\"../dmc21_amazon_validation.csv\", engine=\"python\")\n",
    "amazon_test = pd.read_csv(\"../dmc21_amazon_test.csv\", engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "amazon_val_ids = amazon_val[\"itemID\"].values.tolist()\n",
    "amazon_val_ids = [np.int64(a) for a in amazon_val_ids]\n",
    "len(amazon_val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "amazon_test_ids = amazon_test[\"itemID\"].values.tolist()\n",
    "amazon_test_ids = [np.int64(i) for i in amazon_test_ids]\n",
    "len(amazon_test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(path: str) -> dict:\n",
    "    #if emb not in [\"title\", \"book\", \"author\", \"publisher\", \"topic\"]:\n",
    "    #    raise Exception(\"Not known embeddings\")\n",
    "\n",
    "    #path = \"embeddings/%s_embeddings_multilingual.npz\" % emb\n",
    "\n",
    "    embeddings = np.load(path)[\"arr_0\"]\n",
    "\n",
    "    item_ids = items_c[\"itemID\"].values.tolist()\n",
    "    item_ids = [np.int64(i) for i in item_ids]\n",
    "\n",
    "    emb_dict = {}\n",
    "\n",
    "    for i in range(len(item_ids)):\n",
    "        emb_dict[item_ids[i]] = embeddings[i]\n",
    "\n",
    "    return emb_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_emb = create_embeddings(path=\"embeddings/book_embeddings.npz\")\n",
    "title_emb = create_embeddings(path=\"embeddings/title_embeddings.npz\")\n",
    "author_emb = create_embeddings(path=\"embeddings/author_embeddings.npz\")\n",
    "publisher_emb = create_embeddings(path=\"embeddings/publisher_embeddings.npz\")\n",
    "topic_emb = create_embeddings(path=\"embeddings/topic_embeddings.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_chars = [\n",
    "    \"\\n\",\n",
    "    \"\\r\",\n",
    "    \"!\",\n",
    "    '\"',\n",
    "    \"#\",\n",
    "    \"$\",\n",
    "    \"%\",\n",
    "    \"&\",\n",
    "    \"'\",\n",
    "    \"(\",\n",
    "    \")\",\n",
    "    \"*\",\n",
    "    \"+\",\n",
    "    \",\",\n",
    "    \"-\",\n",
    "    \".\",\n",
    "    \"/\",\n",
    "    \":\",\n",
    "    \";\",\n",
    "    \"=\",\n",
    "    \">\",\n",
    "    \"?\",\n",
    "    \"@\",\n",
    "    \"[\",\n",
    "    \"]\",\n",
    "    \"_\",\n",
    "    \"`\",\n",
    "    \"|\",\n",
    "    \"~\",\n",
    "    \"\\x81\",\n",
    "    \"\\x8e\",\n",
    "    \"\\x92\",\n",
    "    \"\\xa0\",\n",
    "    \"¡\",\n",
    "    \"©\",\n",
    "    \"«\",\n",
    "    \"¬\",\n",
    "    \"®\",\n",
    "    \"°\",\n",
    "    \"¶\",\n",
    "    \"»\",\n",
    "    \"÷\",\n",
    "]\n",
    "\n",
    "replace_chars = {\n",
    "    \"¹\": \"1\",\n",
    "    \"²\": \"2\",\n",
    "    \"³\": \"3\",\n",
    "    \"à\": \"a\",\n",
    "    \"á\": \"a\",\n",
    "    \"â\": \"a\",\n",
    "    \"ã\": \"a\",\n",
    "    \"å\": \"a\",\n",
    "    \"æ\": \"a\",\n",
    "    \"ç\": \"c\",\n",
    "    \"è\": \"e\",\n",
    "    \"é\": \"e\",\n",
    "    \"ê\": \"e\",\n",
    "    \"ë\": \"e\",\n",
    "    \"ì\": \"i\",\n",
    "    \"í\": \"i\",\n",
    "    \"î\": \"i\",\n",
    "    \"ï\": \"i\",\n",
    "    \"ñ\": \"n\",\n",
    "    \"ò\": \"o\",\n",
    "    \"ó\": \"o\",\n",
    "    \"ô\": \"o\",\n",
    "    \"õ\": \"o\",\n",
    "    \"ø\": \"o\",\n",
    "    \"ù\": \"u\",\n",
    "    \"ú\": \"u\",\n",
    "    \"û\": \"u\",\n",
    "    \"ý\": \"y\",\n",
    "    \"ÿ\": \"y\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanse_string(string_: str):\n",
    "    substrings = string_.split()\n",
    "    substrings[:] = [s.lower() for s in substrings]\n",
    "    for sc in special_chars:\n",
    "        substrings[:] = [s.replace(sc, \"\") for s in substrings]\n",
    "    for key, val in replace_chars.items():\n",
    "        substrings[:] = [s.replace(key, val) for s in substrings]\n",
    "    substrings = list(filter(None, substrings))\n",
    "    return \" \".join(substrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"publisher_dict.json\") as f:\n",
    "    data = f.read()\n",
    "publisher_dict = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "publisher_dict_2 = dict()\n",
    "for k, v in publisher_dict.items():\n",
    "    topic = cleanse_string(str(k))\n",
    "    publisher_dict_2[topic] = cleanse_string(str(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'children’s teenage fiction fantasy'"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "publisher_dict_2[\"yfh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     itemID                title        author publisher main topic subtopics\n",
       "440     445  phantastische reise  isaac asimov    epubli         fl       NaN"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>itemID</th>\n      <th>title</th>\n      <th>author</th>\n      <th>publisher</th>\n      <th>main topic</th>\n      <th>subtopics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>440</th>\n      <td>445</td>\n      <td>phantastische reise</td>\n      <td>isaac asimov</td>\n      <td>epubli</td>\n      <td>fl</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "items_c[items_c[\"itemID\"] == np.int64(445)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(embeddings: dict, book_id_1: np.int64(), book_id_2: np.int64) -> float:\n",
    "    sim = float(0)\n",
    "    embeddings = embeddings\n",
    "    sim = cosine(embeddings[book_id_1], embeddings[book_id_2])\n",
    "    return round(1 - sim, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.52"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "cosine_sim(embeddings=book_emb, book_id_1=np.int64(75539), book_id_2=np.int64(666))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyjarowinkler import distance\n",
    "\n",
    "\n",
    "def jaro_winkler_sim(string_1: str, string_2: str) -> float:\n",
    "    return distance.get_jaro_distance(string_1, string_2, winkler=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "75539"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "test_eval = eval_.at[420, \"itemID\"]\n",
    "test_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(item_id: np.int64(), **kwargs) -> tuple:\n",
    "    attributes_ = {}\n",
    "    similarities = []\n",
    "\n",
    "    book_entry = items.loc[items[\"itemID\"] == item_id].reset_index()\n",
    "    book_entry_c = items_c[items_c[\"itemID\"] == item_id].reset_index()\n",
    "\n",
    "    author = str(book_entry_c.at[0, \"author\"])\n",
    "    title = str(book_entry_c.at[0, \"title\"])\n",
    "    publisher = str(book_entry_c.at[0, \"publisher\"])\n",
    "    topic = str(book_entry_c.at[0, \"main topic\"])\n",
    "    #if str(book_entry_c.at[0, \"main topic\"]) != \"nan\":\n",
    "    #    topic = publisher_dict_2[str(book_entry_c.at[0, \"main topic\"])]\n",
    "    #else:\n",
    "    #    topic = str(book_entry_c.at[0, \"main topic\"])\n",
    "\n",
    "    for k, v in kwargs.items():\n",
    "        attributes_[k] = v\n",
    "\n",
    "    weights_sum = 0\n",
    "    for k, v in attributes_.items():\n",
    "        weights_sum += attributes_[k][0]\n",
    "    if round(weights_sum, 1) != 1.0:\n",
    "        raise Exception(\"sum of weights unequal to 1.0\")\n",
    "\n",
    "    for i in items_dedup_c.index:\n",
    "        book_id_comp = items_dedup_c.at[i, \"itemID\"]\n",
    "\n",
    "        author_comp = str(items_dedup_c.at[i, \"author\"])\n",
    "        title_comp = str(items_dedup_c.at[i, \"title\"])\n",
    "        publisher_comp = str(items_dedup_c.at[i, \"publisher\"])\n",
    "        topic_comp = str(items_dedup_c.at[i, \"main topic\"])\n",
    "        #if str(items_dedup_c.at[i, \"main topic\"]) != \"nan\":\n",
    "        #    topic_comp = publisher_dict_2[str(items_dedup_c.at[i, \"main topic\"])]\n",
    "        #else:\n",
    "        #    topic_comp = str(items_dedup_c.at[i, \"main topic\"])\n",
    "\n",
    "        author_sim = 0\n",
    "        title_sim = 0\n",
    "        publisher_sim = 0\n",
    "        topic_sim = 0\n",
    "        book_sim = 0\n",
    "\n",
    "        sim_scores = []\n",
    "\n",
    "        if \"book\" in attributes_.keys():\n",
    "            book_sim = cosine_sim(\n",
    "                embeddings=book_emb, book_id_1=item_id, book_id_2=np.int64(book_id_comp)\n",
    "            )\n",
    "        else:\n",
    "            if \"author\" in attributes_.keys():\n",
    "                if attributes_[\"author\"][1] == cosine_sim:\n",
    "                    author_sim = cosine_sim(embeddings=author_emb, book_id_1=item_id, book_id_2=np.int64(book_id_comp))\n",
    "                    sim_scores.append(tuple([attributes_[\"author\"][0], author_sim]))\n",
    "                else:\n",
    "                    author_sim = attributes_[\"author\"][1](author, author_comp)\n",
    "                    sim_scores.append(tuple([attributes_[\"author\"][0], author_sim]))\n",
    "            if \"title\" in attributes_.keys():\n",
    "                if attributes_[\"title\"][1] == cosine_sim:\n",
    "                    title_sim = cosine_sim(embeddings=title_emb, book_id_1=item_id, book_id_2=np.int64(book_id_comp))\n",
    "                    sim_scores.append(tuple([attributes_[\"title\"][0], title_sim]))\n",
    "                else:\n",
    "                    title_sim = attributes_[\"title\"][1](title, title_comp)\n",
    "                    sim_scores.append(tuple([attributes_[\"title\"][0], title_sim]))\n",
    "            if \"publisher\" in attributes_.keys():\n",
    "                if attributes_[\"publisher\"][1] == cosine_sim:\n",
    "                    publisher_sim = cosine_sim(embeddings=publisher_emb, book_id_1=item_id, book_id_2=np.int64(book_id_comp))\n",
    "                    sim_scores.append([attributes_[\"publisher\"][0], publisher_sim])\n",
    "                else:\n",
    "                    publisher_sim = attributes_[\"publisher\"][1](\n",
    "                        publisher, publisher_comp\n",
    "                    )\n",
    "                    sim_scores.append(\n",
    "                        tuple([attributes_[\"publisher\"][0], publisher_sim])\n",
    "                    )\n",
    "            if \"topic\" in attributes_.keys():\n",
    "                if attributes_[\"topic\"][1] == cosine_sim:\n",
    "                    topic_sim = cosine_sim(embeddings=topic_emb, book_id_1=item_id, book_id_2=np.int64(book_id_comp))\n",
    "                    sim_scores.append(tuple([attributes_[\"topic\"][0], topic_sim]))\n",
    "                else:\n",
    "                    topic_sim = attributes_[\"topic\"][1](topic, topic_comp)\n",
    "                    sim_scores.append(tuple([attributes_[\"topic\"][0], topic_sim]))\n",
    "\n",
    "        if \"book\" not in attributes_.keys():\n",
    "            for sim_score in sim_scores:\n",
    "                book_sim += sim_score[0] * sim_score[1]\n",
    "\n",
    "        if book_sim == float(1):\n",
    "            continue\n",
    "        if len(similarities) < 7:\n",
    "            similarities.append(tuple([book_id_comp, book_sim]))\n",
    "        else:\n",
    "            book_sims = [x[1] for x in similarities]\n",
    "            if all(book_sim >= s[1] for s in similarities):\n",
    "                similarities.append(tuple([book_id_comp, book_sim]))\n",
    "            similarities.sort(key=lambda s: s[1], reverse=True)\n",
    "            similarities = similarities[:7]\n",
    "\n",
    "    recommendations = items[items[\"itemID\"].isin([s[0] for s in similarities])]\n",
    "    recommendations[\"sim\"] = np.nan\n",
    "    for e in [s for s in similarities]:\n",
    "        recommendations.loc[(recommendations[\"itemID\"] == e[0]), \"sim\"] = e[1]\n",
    "    return book_entry, recommendations.sort_values(by=[\"sim\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = get_recommendations(test_eval, author=(0.25, jaro_winkler_sim), title=(0.25, jaro_winkler_sim), topic=(0.25, jaro_winkler_sim), publisher=(0.25, jaro_winkler_sim))\n",
    "# r = get_recommendations(test_eval, title=((1/3), cosine_sim), author=((1/3), cosine_sim), topic=((1/3), cosine_sim))\n",
    "r = get_recommendations(test_eval, book=(1.0, cosine_sim))\n",
    "display(r[0])\n",
    "display(r[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "eval_books=eval_[\"itemID\"].values.tolist()\n",
    "eval_books=[np.int64(a) for a in eval_books]\n",
    "len(eval_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_val_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n"
     ]
    }
   ],
   "source": [
    "for i, e in enumerate(eval_books):\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    recommendations = get_recommendations(e, author=(0.25, jaro_winkler_sim), title=(0.25, jaro_winkler_sim), topic=(0.25, jaro_winkler_sim), publisher=(0.25, jaro_winkler_sim))\n",
    "    r = recommendations[1][\"itemID\"].values.tolist()\n",
    "    book_val_dict[e]=r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "len(book_val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of books with recommendations in validation set: 232 of 232\nAverage number of recommendations per book in validation set: 3.9\nPrecision@1: 36.21%\nRecall@1: 12.93%\nF1-Measure@1: 17.07%\n-------\nPrecision@2: 26.72%\nRecall@2: 16.77%\nF1-Measure@2: 18.34%\n-------\nPrecision@3: 19.83%\nRecall@3: 18.1%\nF1-Measure@3: 16.9%\n-------\nPrecision@5: 12.67%\nRecall@5: 19.2%\nF1-Measure@5: 13.74%\n-------\nPrecision@6: 10.63%\nRecall@6: 19.31%\nF1-Measure@6: 12.42%\n-------\nPrecision@7: 9.11%\nRecall@7: 19.31%\nF1-Measure@7: 11.28%\n-------\nMean Average Precision: 17.16%\n"
     ]
    }
   ],
   "source": [
    "from evaluation_workflow import evaluate_recommender\n",
    "evaluate_recommender(book_val_dict, \"dmc21_amazon_validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of books with recommendations in validation set: 232 of 232\nAverage number of recommendations per book in validation set: 3.9\nPrecision@1: 36.21%\nRecall@1: 12.93%\nF1-Measure@1: 17.07%\n-------\nPrecision@2: 26.72%\nRecall@2: 16.77%\nF1-Measure@2: 18.34%\n-------\nPrecision@3: 19.83%\nRecall@3: 18.1%\nF1-Measure@3: 16.9%\n-------\nPrecision@5: 12.67%\nRecall@5: 19.2%\nF1-Measure@5: 13.74%\n-------\nPrecision@6: 10.63%\nRecall@6: 19.31%\nF1-Measure@6: 12.42%\n-------\nPrecision@7: 9.11%\nRecall@7: 19.31%\nF1-Measure@7: 11.28%\n-------\nMean Average Precision: 17.16%\n"
     ]
    }
   ],
   "source": [
    "evaluate_recommender(data, \"dmc21_amazon_validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_val_dict2 = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n"
     ]
    }
   ],
   "source": [
    "for i, e in enumerate(amazon_val_ids):\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    recommendations = get_recommendations(e, book=(1.0, cosine))\n",
    "    r = recommendations[1][\"itemID\"].values.tolist()\n",
    "    book_val_dict2[e]=r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of books with recommendations in validation set: 232 of 232\nAverage number of recommendations per book in validation set: 3.9\nPrecision@1: 22.84%\nRecall@1: 7.11%\nF1-Measure@1: 9.97%\n-------\nPrecision@2: 17.24%\nRecall@2: 10.47%\nF1-Measure@2: 11.77%\n-------\nPrecision@3: 13.22%\nRecall@3: 11.59%\nF1-Measure@3: 11.2%\n-------\nPrecision@5: 9.22%\nRecall@5: 12.9%\nF1-Measure@5: 9.86%\n-------\nPrecision@6: 7.97%\nRecall@6: 13.6%\nF1-Measure@6: 9.22%\n-------\nPrecision@7: 7.08%\nRecall@7: 14.03%\nF1-Measure@7: 8.67%\n-------\nMean Average Precision: 10.98%\n"
     ]
    }
   ],
   "source": [
    "from evaluation_workflow import evaluate_recommender\n",
    "evaluate_recommender(book_val_dict2, \"dmc21_amazon_validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_emb_recom = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n"
     ]
    }
   ],
   "source": [
    "for i, e in enumerate(eval_books):\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    recommendations = get_recommendations(e, author=(0.25, jaro_winkler_sim), title=(0.25, jaro_winkler_sim), topic=(0.25, jaro_winkler_sim), publisher=(0.25, jaro_winkler_sim))\n",
    "    r = recommendations[1][\"itemID\"].values.tolist()\n",
    "    book_emb_recom[e]=r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "len(book_emb_recom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## jaro winkler standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of books with recommendations in validation set: 232 of 232\nAverage number of recommendations per book in validation set: 3.9\nPrecision@1: 4.74%\nRecall@1: 1.42%\nF1-Measure@1: 2.03%\n-------\nPrecision@2: 12.5%\nRecall@2: 8.75%\nF1-Measure@2: 9.15%\n-------\nPrecision@3: 10.92%\nRecall@3: 10.62%\nF1-Measure@3: 9.64%\n-------\nPrecision@5: 7.16%\nRecall@5: 11.16%\nF1-Measure@5: 7.88%\n-------\nPrecision@6: 6.03%\nRecall@6: 11.27%\nF1-Measure@6: 7.15%\n-------\nPrecision@7: 5.17%\nRecall@7: 11.27%\nF1-Measure@7: 6.48%\n-------\nMean Average Precision: 6.42%\n"
     ]
    }
   ],
   "source": [
    "from evaluation_workflow import evaluate_recommender\n",
    "evaluate_recommender(book_emb_recom, \"dmc21_amazon_validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## book embeddings standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of books with recommendations in validation set: 232 of 232\nAverage number of recommendations per book in validation set: 3.9\nPrecision@1: 22.84%\nRecall@1: 7.11%\nF1-Measure@1: 9.97%\n-------\nPrecision@2: 17.24%\nRecall@2: 10.47%\nF1-Measure@2: 11.77%\n-------\nPrecision@3: 13.22%\nRecall@3: 11.59%\nF1-Measure@3: 11.2%\n-------\nPrecision@5: 9.22%\nRecall@5: 12.9%\nF1-Measure@5: 9.86%\n-------\nPrecision@6: 7.97%\nRecall@6: 13.6%\nF1-Measure@6: 9.22%\n-------\nPrecision@7: 7.08%\nRecall@7: 14.03%\nF1-Measure@7: 8.67%\n-------\nMean Average Precision: 10.98%\n"
     ]
    }
   ],
   "source": [
    "from evaluation_workflow import evaluate_recommender\n",
    "evaluate_recommender(book_emb_recom, \"dmc21_amazon_validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_emb_recom_new = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n"
     ]
    }
   ],
   "source": [
    "for i, e in enumerate(eval_books):\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    recommendations = get_recommendations(e, book=(1.0, cosine_sim))\n",
    "    r = sorted(recommendations[1][\"itemID\"].values.tolist())\n",
    "    book_emb_recom_new[e]=r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_emb_jaro = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "10\n",
      "20\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-0c6a3081f00b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mrecommendations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_recommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaro_winkler_sim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaro_winkler_sim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaro_winkler_sim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublisher\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaro_winkler_sim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecommendations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"itemID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbook_emb_jaro\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-46885fc1a807>\u001b[0m in \u001b[0;36mget_recommendations\u001b[0;34m(item_id, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m                     \u001b[0msim_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattributes_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"publisher\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublisher_sim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                     publisher_sim = attributes_[\"publisher\"][1](\n\u001b[0m\u001b[1;32m     63\u001b[0m                         \u001b[0mpublisher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublisher_comp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                     )\n",
      "\u001b[0;32m<ipython-input-14-8c1e7c705b8e>\u001b[0m in \u001b[0;36mjaro_winkler_sim\u001b[0;34m(string_1, string_2)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mjaro_winkler_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring_1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_jaro_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwinkler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/environs/env1/lib/python3.8/site-packages/pyjarowinkler/distance.py\u001b[0m in \u001b[0;36mget_jaro_distance\u001b[0;34m(first, second, winkler, winkler_ajustment, scaling)\u001b[0m\n\u001b[1;32m     30\u001b[0m             second.__class__.__name__))\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mjaro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mcl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environs/env1/lib/python3.8/site-packages/pyjarowinkler/distance.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(first, second)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mlonger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshorter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshorter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlonger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_matching_characters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshorter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlonger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mm2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_matching_characters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlonger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshorter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environs/env1/lib/python3.8/site-packages/pyjarowinkler/distance.py\u001b[0m in \u001b[0;36m_get_matching_characters\u001b[0;34m(first, second)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msecond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msecond\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, e in enumerate(eval_books):\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    recommendations = get_recommendations(e, author=(0.25, jaro_winkler_sim), title=(0.25, jaro_winkler_sim), topic=(0.25, jaro_winkler_sim), publisher=(0.25, jaro_winkler_sim))\n",
    "    r = sorted(recommendations[1][\"itemID\"].values.tolist())\n",
    "    book_emb_jaro[e]=r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, e in enumerate(eval_books):\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    recommendations = get_recommendations(e, book=(1.0, cosine_sim))\n",
    "    r = sorted(recommendations[1][\"itemID\"].values.tolist())\n",
    "    book_emb_recom_new[e]=r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_workflow import evaluate_recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of books with recommendations in validation set: 232 of 232\nAverage number of recommendations per book in validation set: 3.9\nPrecision@1: 2.59%\nRecall@1: 0.56%\nF1-Measure@1: 0.88%\n-------\nPrecision@2: 2.37%\nRecall@2: 0.97%\nF1-Measure@2: 1.32%\n-------\nPrecision@3: 2.73%\nRecall@3: 1.65%\nF1-Measure@3: 1.98%\n-------\nPrecision@5: 3.88%\nRecall@5: 5.09%\nF1-Measure@5: 4.0%\n-------\nPrecision@6: 4.67%\nRecall@6: 7.49%\nF1-Measure@6: 5.27%\n-------\nPrecision@7: 7.08%\nRecall@7: 14.03%\nF1-Measure@7: 8.67%\n-------\nMean Average Precision: 3.98%\n"
     ]
    }
   ],
   "source": [
    "evaluate_recommender(book_emb_recom, \"dmc21_amazon_validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of books with recommendations in validation set: 232 of 232\nAverage number of recommendations per book in validation set: 3.9\nPrecision@1: 0.86%\nRecall@1: 0.3%\nF1-Measure@1: 0.43%\n-------\nPrecision@2: 0.43%\nRecall@2: 0.3%\nF1-Measure@2: 0.34%\n-------\nPrecision@3: 0.72%\nRecall@3: 0.69%\nF1-Measure@3: 0.67%\n-------\nPrecision@5: 1.98%\nRecall@5: 2.09%\nF1-Measure@5: 1.95%\n-------\nPrecision@6: 3.59%\nRecall@6: 4.53%\nF1-Measure@6: 3.87%\n-------\nPrecision@7: 6.71%\nRecall@7: 13.53%\nF1-Measure@7: 8.26%\n-------\nMean Average Precision: 2.98%\n"
     ]
    }
   ],
   "source": [
    "evaluate_recommender(book_emb_recom_new, \"dmc21_amazon_validation.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('env1': virtualenvwrapper)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "9ef5468a5c3446d919a3df41ce23b00652fe3710922e53e14080c28e3bcfe2d6"
   }
  },
  "interpreter": {
   "hash": "9ef5468a5c3446d919a3df41ce23b00652fe3710922e53e14080c28e3bcfe2d6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}